# YoloStudyRoute
YOLO学习路线

+ 目标检测问题定义
  + 目标检测是在图片中对可变数量的目标进行查找和分类
    + 目标种类和数量问题
    + 目标尺度问题
    + 外在环境干扰问题 
  + 深度学习目标检测方法
    + 特点
      + 深度网络学习特征
      + Proposal或者直接回归
      + 深度网络
      + 端到端
      + 准确度高和实时性好
    + One-stage(YOLO 和 SSD系列)
      + 特点
        + 使用CNN卷积特征
        + 直接回归物体的类别概率和位置坐标值（无region proposal）
        + 准确度地、速度相对two-stage快
      + Input -> CNN -> Lreg、Lcls
        + CNN特征 -> 区域分类、位置精修
      + 核心组件
        + CNN网络
        + 回归网络
          + 区域回归（置信度、位置、类别）
          + Anchor机制（SSD）
    + Two-stage(Faster RCNN系列)
      + CNN卷积特征
      + 端到端的目标检测（RPN网络）
      + 准确度高、速度相对one-stage慢
      + input -> conv&pooling -> conv -> roi_pooling -> fc
        + 产生候选区域CNN特征 -> 区域分类、位置精修
      + 核心组件
        + CNN网络
          + 从简到繁再到简的卷积神经网
          + 多尺度特征融合的网络
          + 更轻量级的CNN网络
        + RPN网络
          + 区域推荐（Anchor机制）
          + ROI Pooling
          + 分类和回归  
      + 改进方向
        + 更好的网络特征
        + 更精准的RPN
        + 更完善的ROI分类
        + 样本后处理
        + 更大的mini-Batch
  
+ 物体检测
  + 物体检测用于定位图像中的多个不同类别的物体
  + 定位 + 分类
  + 算法性能的评价
    + TP: 标注框重叠率很高
    + FP: 重叠率低（甚至没有重叠）和重复检测的框
    + precision 和 recall
    + AP 和 mAP：
      + mAP：综合考量检测效果指标
      + mAP: 
    + FPS: 代表算法的速度
    + IOU指标：交集和并集的比值。（真实值和预测值的比值）
    + 精度代表查准率，召回代表查全率
  + 物体检测业务场景
    + 传统: 候选框  -> 特征提取 -> 分类器判定目标or背景
    + 现今: 特征提取 -> 直接回归 
  + 数据集资源
    + Pascal VOC: 20个类别
    + COCO: 91个类别，小目标多，单幅图片目标多，物体大多非中心分布，更符合日常环境，coco检测难度更大
    + ILSVRC2012：Imagenet数据集有1400多万幅图片，涵盖2万多个类别；其中有超过百万的图片有明确的类别标准和图像中物体位置的标准。  
+ 开发流程
  + 项目预研 + 算法选型 + 数据集下载和打包 + 环境搭建 + 模型训练 + 模型测试 + 模型优化
+ YOLO算法（one-stage算法）
  + 特点
    + 同时预测多个BOX位置和类别
    + 端到端的目标检测和识别
    + 速度更快
      + 实现回归功能的CNN并不需要复杂的设计过程
      + 直接选用整图训练模型，更好的区分目标和背景区域
    + 精度偏差
  + YOLOV1算法
    + 特点
      +  图像被分成S*S个格子
      +  包含GT物体中心的格子负责检测相应的物体
      +  每个格子预测B个检测框及其置信度，以及C个类别概率
      +  bbox信息（x,y,w,h）为物体的中心位置相对格子位置的偏移及宽度和高度，均被归一化。
    +  置信度反映是否包含物体以及包含物体情况下位置的准确性
    + 网络结构分析
      + 网络使用更小卷积。即：1*1 和 3*3 
      + FC输出为 S *S (B*5 +C)
      + 网络比VGG16快，准确率稍差
    + 损失函数
      + LOSS函数：均方和误差
      + 坐标误差、IOU误差和分类误差
      + 权重考量
    + 网络训练
      + 预训练。ImageNet 1000类数据预训练
      + 使用预训练参数（20个con）来初始化YOLO，并训练VOC20
      + 将输入图像分辨率从224*224 Resize到 448*448
      + 训练时B个bbox的GT设置相同
    + 网络存在的问题
      + 输入尺寸固定
      + 小目标检测效果差
        + 同一各自包含多个目标时，仅预测一个（IOU最高）
  + YOLOV2 算法
    + 特点
      + 引入了anchor box的思想
      + 输出层：卷积层替代YOLO V1的全连接层
      + 联合使用coco 和 imagenet物体分类标注数据
      + 识别种类，精度、速度和定位准确性等都有大幅提升
    + 改进
      + Batch Normalization: v2中取消了Drop out 均使用BN
      + 高分辨率分类器：以448*448的分辨率微调最初的分类网络
      + Anchors Boxes：使用卷积代替FC，输入尺度：416，max pooling下采样，预测超过1000个，mAP降低，recall显著提高
      + 细粒度特征：添加pass through layer,把浅层特征图（26*26）链接到深层特征图，Resnet中的identity mapping。把26*26*512 的特征图叠加成13*13*2048的特征图，与深层特征图相连接，增加细粒度特征
      + Multi-Scale Training：每隔几次迭代后就会微调网络的输入尺寸。尺度的变化
    + 网络结构
      + 主要使用 3*3卷积
      + pooling之后channel数加
      + global average pooling 
      + 1 *1 卷积压缩特征表示
      + batch normalization
  + YOLOV3 算法 
    + 特点
      + 速度和精度最均衡的目标检测网络
      + 融合多种先进方法，改进YOLO V1 /V2 缺点，且效果更优。重点解决小物体检测问题。
    + 改进策略
      + 更好的主干网络（类ResNet）
      + 多尺度预测（类FPN）
      + 更好的分类器
    + 借用DarkNet框架
      + 由C语言和CUDA实现
      + GPU显存利用效率较高
      + 第三方库的依赖较少
      + 容易移植到其他平台，如windows或嵌入设备
    + DarkNet
      + 一个较为轻型的完全基于C与CUDA的开源深度学习框架
      + 容易安装，没有任何依赖项，移植性非常好，支持CPU与GPU两种计算方式
      + darknet完全由C语言实现，没有任何依赖项，当然可以使用opencv，但只是用其来显示图片，为了更好的可视化
      + darknet支持CPU与GPU
      + 轻量型、灵活性，适合用来研究底层，可以更为方便的呢从底层对其进行改进与扩展
      + darknet的实现与caffe的实现存在相似的地方
    + 
  + 基本流程
  + 主干网络结构
  + 设计思路
